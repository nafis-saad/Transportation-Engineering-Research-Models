{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71904ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0053692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fe44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Courses\\CE 7090 -Statistical and Econometric Methods in Civil Engineering II\\HomeWork\\HW-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94da31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, treating -999 as NaN (missing)\n",
    "df = pd.read_csv('HW4 Data.txt', delim_whitespace=True, header=None, na_values=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648ce101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 49)\n",
      "   3   24  33\n",
      "0   0  63  60\n",
      "1   0   0  60\n",
      "2   0  16  55\n",
      "3   1  30  60\n",
      "4   1  53  60\n"
     ]
    }
   ],
   "source": [
    "# Basic inspection\n",
    "print(df.shape)        # should be (999, 49)\n",
    "print(df[[3,24,33]].head())  # peek at severity (X4), age (X25), speed limit (X34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fda21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21    879\n",
      "26     27\n",
      "27     27\n",
      "29     12\n",
      "37    619\n",
      "39    180\n",
      "40    180\n",
      "41    180\n",
      "42    180\n",
      "43    180\n",
      "44    180\n",
      "45    916\n",
      "46    715\n",
      "47    715\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing_counts = df.isna().sum()\n",
    "print(missing_counts[missing_counts > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f3d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(982, 44)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with > 500 missing values (arbitrary threshold, e.g., X22, X46, X47, X48)\n",
    "cols_to_drop = [col for col in df.columns if df[col].isna().sum() > 500]\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop rows where age (X25) is missing or zero (assuming 0 means unknown age)\n",
    "df = df[df[24] != 0]  # X25 (driver age) is at index 24\n",
    "\n",
    "# Verify remaining shape after drops\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a74b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert certain codes to categories or create dummies\n",
    "df[5] = df[5].astype('category')        # X6 City (Seattle or not)\n",
    "df[16] = df[16].astype('category')      # X17 Sobriety codes as category\n",
    "df['winter'] = df[8].isin([12, 1, 2]).astype(int)      # X9 (month) in {12,1,2}\n",
    "df['fix_obj'] = (df[17] == 50).astype(int)             # X18 collision type 50\n",
    "df['young_driver'] = (df[24] <= 25).astype(int)        # X25 age <= 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca32fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    982.000000\n",
      "mean      34.983707\n",
      "std       15.092570\n",
      "min       16.000000\n",
      "25%       23.000000\n",
      "50%       30.000000\n",
      "75%       45.000000\n",
      "max       85.000000\n",
      "Name: 24, dtype: float64\n",
      "3\n",
      "0    705\n",
      "1    248\n",
      "2     22\n",
      "3      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[24].describe())    # driver age stats\n",
    "print(df[3].value_counts()) # severity counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d832bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3                     0          1          2         3\n",
      "no_restraint                                           \n",
      "0             72.164948  25.257732   1.958763  0.618557\n",
      "1             41.666667  25.000000  25.000000  8.333333\n"
     ]
    }
   ],
   "source": [
    "# Example: proportion of severe outcomes when no seatbelt vs seatbelt used\n",
    "df['no_restraint'] = (df[27] == 3).astype(int)  # X28 code 3 = no restraints used\n",
    "print(pd.crosstab(df['no_restraint'], df[3], normalize='index') * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e944e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a76efb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7a6c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.697894\n",
      "         Iterations: 31\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n",
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:                      3   Log-Likelihood:                -685.33\n",
      "Model:                   OrderedModel   AIC:                             1385.\n",
      "Method:            Maximum Likelihood   BIC:                             1419.\n",
      "Date:                Sun, 16 Mar 2025                                         \n",
      "Time:                        20:45:25                                         \n",
      "No. Observations:                 982                                         \n",
      "Df Residuals:                     975                                         \n",
      "Df Model:                           4                                         \n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "winter          -0.1733      0.092     -1.888      0.059      -0.353       0.007\n",
      "fix_obj         -0.0749      0.110     -0.681      0.496      -0.291       0.141\n",
      "young_driver     0.0620      0.086      0.719      0.472      -0.107       0.231\n",
      "no_restraint     1.0963      0.321      3.411      0.001       0.466       1.726\n",
      "0/1              0.5003      0.104      4.811      0.000       0.296       0.704\n",
      "1/2              0.2918      0.061      4.758      0.000       0.172       0.412\n",
      "2/3             -0.5202      0.212     -2.458      0.014      -0.935      -0.105\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define outcome and predictors\n",
    "y = df['severity'] = df[3]  # X4 Injury severity\n",
    "X = df[['winter', 'fix_obj', 'young_driver', 'no_restraint']]  # example predictors\n",
    "# Note: If needed, add others like alcohol or speed_limit. Here for illustration, using a few.\n",
    "\n",
    "# Fit ordered probit (probit link for ordinal) \n",
    "model = OrderedModel(y, X, distr='probit')\n",
    "result = model.fit(method='bfgs')\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be02af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d8cb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Log-likelihood = -5208.9729, ll_change = inf, param_change = 0.000000\n",
      "Iteration 1: Log-likelihood = -5208.9729, ll_change = 0.000000, param_change = 0.000000\n",
      "Converged at iteration 1\n",
      "Final Mixing Proportions: [0.49804541 0.50195459]\n",
      "\n",
      "Class 1 Coefficients:\n",
      "winter         -0.173256\n",
      "fix_obj        -0.074944\n",
      "young_driver    0.062003\n",
      "no_restraint    1.096298\n",
      "dtype: float64\n",
      "Class 1 Thresholds:\n",
      "0/1    0.500270\n",
      "1/2    0.291836\n",
      "2/3   -0.520236\n",
      "dtype: float64\n",
      "\n",
      "Class 2 Coefficients:\n",
      "winter         -0.173256\n",
      "fix_obj        -0.074944\n",
      "young_driver    0.062003\n",
      "no_restraint    1.096298\n",
      "dtype: float64\n",
      "Class 2 Thresholds:\n",
      "0/1    0.500270\n",
      "1/2    0.291836\n",
      "2/3   -0.520236\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "max_iter = 100\n",
    "tol_ll = 1e-4       # tolerance for log-likelihood change\n",
    "tol_params = 1e-4   # tolerance for parameter change\n",
    "prev_ll = -np.inf\n",
    "N = len(df)\n",
    "K = 2\n",
    "\n",
    "# Randomly initialize responsibilities\n",
    "np.random.seed(42)\n",
    "r = np.zeros((N, K))\n",
    "for i in range(N):\n",
    "    r[i, 0] = np.random.uniform(0.4, 0.6)\n",
    "    r[i, 1] = 1 - r[i, 0]\n",
    "\n",
    "# Initialize placeholders for parameters\n",
    "prev_class_params = [None] * K\n",
    "\n",
    "for iteration in range(max_iter):\n",
    "    # M-step: update model parameters for each class\n",
    "    class_params = []\n",
    "    class_thresholds = []\n",
    "    for c in range(K):\n",
    "        weights = r[:, c]\n",
    "        model_c = OrderedModel(y, X, distr='probit')\n",
    "        res_c = model_c.fit(method='bfgs', weights=weights, disp=False)\n",
    "        # Assume last (model_c.k_levels - 1) parameters are thresholds\n",
    "        n_thresholds = model_c.k_levels - 1\n",
    "        params_c = res_c.params\n",
    "        class_params.append(params_c[:-n_thresholds])\n",
    "        class_thresholds.append(params_c[-n_thresholds:])\n",
    "    \n",
    "    # Update mixing proportions\n",
    "    pi = r.mean(axis=0)\n",
    "    \n",
    "    # E-step: update responsibilities and compute log-likelihood\n",
    "    ll_total = 0\n",
    "    for i in range(N):\n",
    "        L = np.zeros(K)\n",
    "        for c in range(K):\n",
    "            xb = np.dot(X.iloc[i], class_params[c])\n",
    "            # Compute likelihood based on outcome (assuming 4 ordered outcomes: 0,1,2,3)\n",
    "            if y.iloc[i] == 0:\n",
    "                L[c] = norm.cdf(class_thresholds[c][0] - xb)\n",
    "            elif y.iloc[i] == 1:\n",
    "                L[c] = norm.cdf(class_thresholds[c][1] - xb) - norm.cdf(class_thresholds[c][0] - xb)\n",
    "            elif y.iloc[i] == 2:\n",
    "                L[c] = norm.cdf(class_thresholds[c][2] - xb) - norm.cdf(class_thresholds[c][1] - xb)\n",
    "            elif y.iloc[i] == 3:\n",
    "                L[c] = 1 - norm.cdf(class_thresholds[c][-1] - xb)\n",
    "            L[c] = max(L[c], 1e-8)  # avoid zeros\n",
    "        \n",
    "        total = np.sum([pi[c] * L[c] for c in range(K)])\n",
    "        ll_total += np.log(total)\n",
    "        for c in range(K):\n",
    "            r[i, c] = (pi[c] * L[c]) / total\n",
    "\n",
    "    # Check convergence on log-likelihood\n",
    "    ll_change = np.abs(ll_total - prev_ll)\n",
    "    \n",
    "    # Check convergence on parameter estimates if not first iteration\n",
    "    param_change = 0\n",
    "    if iteration > 0:\n",
    "        for c in range(K):\n",
    "            diff = np.abs(class_params[c] - prev_class_params[c])\n",
    "            param_change = max(param_change, np.max(diff))\n",
    "    \n",
    "    print(f\"Iteration {iteration}: Log-likelihood = {ll_total:.4f}, ll_change = {ll_change:.6f}, param_change = {param_change:.6f}\")\n",
    "    \n",
    "    if ll_change < tol_ll and param_change < tol_params:\n",
    "        print(f\"Converged at iteration {iteration}\")\n",
    "        break\n",
    "    \n",
    "    prev_ll = ll_total\n",
    "    prev_class_params = class_params.copy()\n",
    "\n",
    "print(\"Final Mixing Proportions:\", pi)\n",
    "for c in range(K):\n",
    "    print(f\"\\nClass {c+1} Coefficients:\")\n",
    "    print(class_params[c])\n",
    "    print(f\"Class {c+1} Thresholds:\")\n",
    "    print(class_thresholds[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f66992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mixing Proportions:\n",
      "Class 1: 0.4980\n",
      "Class 2: 0.5020\n",
      "\n",
      "Final Model Estimates for Each Class:\n",
      "\n",
      "Class 1 Coefficients:\n",
      "winter         -0.173256\n",
      "fix_obj        -0.074944\n",
      "young_driver    0.062003\n",
      "no_restraint    1.096298\n",
      "dtype: float64\n",
      "Class 1 Thresholds:\n",
      "0/1    0.500270\n",
      "1/2    0.291836\n",
      "2/3   -0.520236\n",
      "dtype: float64\n",
      "\n",
      "Class 2 Coefficients:\n",
      "winter         -0.173256\n",
      "fix_obj        -0.074944\n",
      "young_driver    0.062003\n",
      "no_restraint    1.096298\n",
      "dtype: float64\n",
      "Class 2 Thresholds:\n",
      "0/1    0.500270\n",
      "1/2    0.291836\n",
      "2/3   -0.520236\n",
      "dtype: float64\n",
      "\n",
      "Distribution of Observations by Predicted Class:\n",
      "predicted_class\n",
      "2    982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# After the EM loop has finished:\n",
    "print(\"Final Mixing Proportions:\")\n",
    "for c in range(K):\n",
    "    print(f\"Class {c+1}: {pi[c]:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Model Estimates for Each Class:\")\n",
    "for c in range(K):\n",
    "    print(f\"\\nClass {c+1} Coefficients:\")\n",
    "    print(class_params[c])\n",
    "    print(f\"Class {c+1} Thresholds:\")\n",
    "    print(class_thresholds[c])\n",
    "\n",
    "# Optionally, assign each observation to a class based on the highest responsibility:\n",
    "df['predicted_class'] = np.argmax(r, axis=1) + 1  # +1 to make classes 1-indexed\n",
    "print(\"\\nDistribution of Observations by Predicted Class:\")\n",
    "print(df['predicted_class'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
