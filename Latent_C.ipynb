{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0313c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae58368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b9db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Courses\\CE 7090 -Statistical and Econometric Methods in Civil Engineering II\\HomeWork\\HW-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351747da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HW4 Data.txt', delim_whitespace=True, header=None, na_values=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea47ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 49)\n",
      "   3   24  33\n",
      "0   0  63  60\n",
      "1   0   0  60\n",
      "2   0  16  55\n",
      "3   1  30  60\n",
      "4   1  53  60\n"
     ]
    }
   ],
   "source": [
    "# Basic inspection\n",
    "print(df.shape)        # should be (999, 49)\n",
    "print(df[[3,24,33]].head())  # peek at severity (X4), age (X25), speed limit (X34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2beeda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21    879\n",
      "26     27\n",
      "27     27\n",
      "29     12\n",
      "37    619\n",
      "39    180\n",
      "40    180\n",
      "41    180\n",
      "42    180\n",
      "43    180\n",
      "44    180\n",
      "45    916\n",
      "46    715\n",
      "47    715\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing_counts = df.isna().sum()\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52547b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(982, 44)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with > 500 missing values (arbitrary threshold, e.g., X22, X46, X47, X48)\n",
    "cols_to_drop = [col for col in df.columns if df[col].isna().sum() > 500]\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop rows where age (X25) is missing or zero (assuming 0 means unknown age)\n",
    "df = df[df[24] != 0]  # X25 (driver age) is at index 24\n",
    "\n",
    "# Verify remaining shape after drops\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461163ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684820\n",
      "         Iterations: 40\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "Single-Class Ordered Probit Results:\n",
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:               severity   Log-Likelihood:                -672.49\n",
      "Model:                   OrderedModel   AIC:                             1363.\n",
      "Method:            Maximum Likelihood   BIC:                             1407.\n",
      "Date:                Sun, 16 Mar 2025                                         \n",
      "Time:                        20:52:35                                         \n",
      "No. Observations:                 982                                         \n",
      "Df Residuals:                     973                                         \n",
      "Df Model:                           6                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "adverse_weather    -0.2735      0.084     -3.254      0.001      -0.438      -0.109\n",
      "dark               -0.0476      0.085     -0.559      0.576      -0.215       0.119\n",
      "driver_age         -0.0022      0.003     -0.783      0.434      -0.008       0.003\n",
      "male               -0.0657      0.086     -0.765      0.444      -0.234       0.103\n",
      "ejected             2.8847      0.727      3.965      0.000       1.459       4.311\n",
      "no_restraint        0.7743      0.333      2.327      0.020       0.122       1.427\n",
      "0/1                 0.2957      0.136      2.181      0.029       0.030       0.561\n",
      "1/2                 0.3203      0.062      5.177      0.000       0.199       0.442\n",
      "2/3                -0.3810      0.216     -1.763      0.078      -0.804       0.042\n",
      "===================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:18: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method bfgs is: gtol, norm, epsilon. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Log-likelihood = -1830.6116, ll_change = inf, param_change = 0.000000\n",
      "Iteration 1: Log-likelihood = -1830.6116, ll_change = 0.000000, param_change = 0.000000\n",
      "Converged at iteration 1\n",
      "\n",
      "Final Mixing Proportions: [0.49804541 0.50195459]\n",
      "\n",
      "Class 1 Coefficients:\n",
      "adverse_weather   -0.273485\n",
      "dark              -0.047624\n",
      "driver_age        -0.002171\n",
      "male              -0.065744\n",
      "ejected            2.884690\n",
      "no_restraint       0.774311\n",
      "dtype: float64\n",
      "Class 1 Thresholds:\n",
      "0/1    0.295718\n",
      "1/2    0.320259\n",
      "2/3   -0.380990\n",
      "dtype: float64\n",
      "\n",
      "Class 2 Coefficients:\n",
      "adverse_weather   -0.273485\n",
      "dark              -0.047624\n",
      "driver_age        -0.002171\n",
      "male              -0.065744\n",
      "ejected            2.884690\n",
      "no_restraint       0.774311\n",
      "dtype: float64\n",
      "Class 2 Thresholds:\n",
      "0/1    0.295718\n",
      "1/2    0.320259\n",
      "2/3   -0.380990\n",
      "dtype: float64\n",
      "\n",
      "Distribution of Observations by Predicted Class:\n",
      "predicted_class\n",
      "2    982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset. (Assumes 'HW4 Data.txt' is in the working directory.)\n",
    "# We treat -999 as missing.\n",
    "\n",
    "\n",
    "# For clarity, letâ€™s define column indices (0-indexed) for the variables we need:\n",
    "# X4 (injury severity) is column 3.\n",
    "# X20 (weather conditions) is column 19.\n",
    "# X21 (lighting condition) is column 20.\n",
    "# X25 (driver age) is column 24.\n",
    "# X26 (driver gender) is column 25.\n",
    "# X27 (ejection status) is column 26.\n",
    "# X28 (restraining system) is column 27.\n",
    "\n",
    "# Create a new DataFrame with our variables of interest:\n",
    "# Outcome: injury severity (0,1,2,3)\n",
    "df['severity'] = df[3]\n",
    "\n",
    "# Predictor 1: Adverse Weather (X20)\n",
    "# Code: 1 means clear or partly cloudy. We define adverse weather as any condition not equal to 1.\n",
    "df['adverse_weather'] = (df[19] != 1).astype(int)\n",
    "\n",
    "# Predictor 2: Dark Conditions (X21)\n",
    "# We assume lighting conditions 4, 5, 6 (dark scenarios) are \"dark.\"\n",
    "df['dark'] = df[20].apply(lambda x: 1 if x in [4, 5, 6] else 0)\n",
    "\n",
    "# Predictor 3: Driver's Age (X25)\n",
    "df['driver_age'] = df[24]\n",
    "\n",
    "# Predictor 4: Driver's Gender (X26)\n",
    "# Already coded: 0 = female, 1 = male.\n",
    "df['male'] = df[25]\n",
    "\n",
    "# Predictor 5: Ejection (X27)\n",
    "# For simplicity, we define ejected = 1 if X27 is 2 (partially) or 3 (totally) ejected.\n",
    "df['ejected'] = df[26].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "\n",
    "# Predictor 6: No Restraint (X28)\n",
    "# We define no_restraint = 1 if X28 equals 3 (no restraints used).\n",
    "df['no_restraint'] = (df[27] == 3).astype(int)\n",
    "\n",
    "# Drop any rows with missing values in these new variables or the outcome\n",
    "df_model = df[['severity', 'adverse_weather', 'dark', 'driver_age', 'male', 'ejected', 'no_restraint']].dropna()\n",
    "\n",
    "# Define the outcome and design matrix.\n",
    "y = df_model['severity']\n",
    "# We include a constant automatically via OrderedModel (or add it explicitly).\n",
    "X = df_model[['adverse_weather', 'dark', 'driver_age', 'male', 'ejected', 'no_restraint']]\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Fit a Single-Class Ordered Probit Model\n",
    "# -------------------------------\n",
    "\n",
    "# Fit the ordered probit model using the alternative predictors.\n",
    "model_single = OrderedModel(y, X, distr='probit')\n",
    "result_single = model_single.fit(method='bfgs')\n",
    "print(\"Single-Class Ordered Probit Results:\")\n",
    "print(result_single.summary())\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Outline of a Latent Class Ordered Probit Model via EM\n",
    "# -------------------------------\n",
    "\n",
    "# Here we present a skeleton for a latent class model with 2 classes.\n",
    "# (A full implementation requires a careful likelihood calculation for ordinal data.)\n",
    "max_iter = 100\n",
    "tol_ll = 1e-4\n",
    "tol_params = 1e-4\n",
    "\n",
    "N = len(df_model)\n",
    "K = 2  # We use 2 classes for this example\n",
    "\n",
    "# Random initialization for responsibilities (avoid symmetric 0.5 exactly)\n",
    "np.random.seed(42)\n",
    "r = np.zeros((N, K))\n",
    "for i in range(N):\n",
    "    r[i, 0] = np.random.uniform(0.4, 0.6)\n",
    "    r[i, 1] = 1 - r[i, 0]\n",
    "\n",
    "prev_ll = -np.inf\n",
    "prev_class_params = [None] * K\n",
    "\n",
    "for iteration in range(max_iter):\n",
    "    # --- M-step: Estimate class-specific parameters using weighted ordered probit ---\n",
    "    class_params = []\n",
    "    class_thresholds = []\n",
    "    for c in range(K):\n",
    "        weights = r[:, c]\n",
    "        # Fit an ordered probit model with weights for class c\n",
    "        model_c = OrderedModel(y, X, distr='probit')\n",
    "        res_c = model_c.fit(method='bfgs', weights=weights, disp=False)\n",
    "        n_thresholds = model_c.k_levels - 1\n",
    "        params_c = res_c.params\n",
    "        # Separate coefficients and thresholds (assuming thresholds are the last parameters)\n",
    "        class_params.append(params_c[:-n_thresholds])\n",
    "        class_thresholds.append(params_c[-n_thresholds:])\n",
    "    \n",
    "    # Update mixing proportions\n",
    "    pi = r.mean(axis=0)\n",
    "    \n",
    "    # --- E-step: Update responsibilities and compute overall log-likelihood ---\n",
    "    ll_total = 0\n",
    "    for i in range(N):\n",
    "        L = np.zeros(K)\n",
    "        for c in range(K):\n",
    "            xb = np.dot(X.iloc[i], class_params[c])\n",
    "            # Compute likelihood for observation i in class c based on the ordinal outcome\n",
    "            # We assume 4 ordered outcomes (0, 1, 2, 3):\n",
    "            if y.iloc[i] == 0:\n",
    "                L[c] = norm.cdf(class_thresholds[c][0] - xb)\n",
    "            elif y.iloc[i] == 1:\n",
    "                L[c] = norm.cdf(class_thresholds[c][1] - xb) - norm.cdf(class_thresholds[c][0] - xb)\n",
    "            elif y.iloc[i] == 2:\n",
    "                L[c] = norm.cdf(class_thresholds[c][2] - xb) - norm.cdf(class_thresholds[c][1] - xb)\n",
    "            elif y.iloc[i] == 3:\n",
    "                L[c] = 1 - norm.cdf(class_thresholds[c][-1] - xb)\n",
    "            # Avoid zero likelihoods:\n",
    "            L[c] = max(L[c], 1e-8)\n",
    "        # Total likelihood for observation i across classes:\n",
    "        total_i = np.sum([pi[c] * L[c] for c in range(K)])\n",
    "        ll_total += np.log(total_i)\n",
    "        # Update responsibilities:\n",
    "        for c in range(K):\n",
    "            r[i, c] = (pi[c] * L[c]) / total_i\n",
    "\n",
    "    # Convergence checks on log-likelihood and parameter change\n",
    "    ll_change = np.abs(ll_total - prev_ll)\n",
    "    param_change = 0\n",
    "    if iteration > 0:\n",
    "        for c in range(K):\n",
    "            diff = np.abs(class_params[c] - prev_class_params[c])\n",
    "            param_change = max(param_change, np.max(diff))\n",
    "    \n",
    "    print(f\"Iteration {iteration}: Log-likelihood = {ll_total:.4f}, ll_change = {ll_change:.6f}, param_change = {param_change:.6f}\")\n",
    "    \n",
    "    if ll_change < tol_ll and param_change < tol_params:\n",
    "        print(f\"Converged at iteration {iteration}\")\n",
    "        break\n",
    "    \n",
    "    prev_ll = ll_total\n",
    "    prev_class_params = [cp.copy() for cp in class_params]\n",
    "\n",
    "print(\"\\nFinal Mixing Proportions:\", pi)\n",
    "for c in range(K):\n",
    "    print(f\"\\nClass {c+1} Coefficients:\")\n",
    "    print(class_params[c])\n",
    "    print(f\"Class {c+1} Thresholds:\")\n",
    "    print(class_thresholds[c])\n",
    "    \n",
    "# Optionally, assign each observation to the class with the highest posterior probability:\n",
    "df_model['predicted_class'] = np.argmax(r, axis=1) + 1  # Classes as 1-indexed\n",
    "print(\"\\nDistribution of Observations by Predicted Class:\")\n",
    "print(df_model['predicted_class'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
